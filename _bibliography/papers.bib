---
---

@inproceedings{puglisi2024enhancing,
   author    = {Puglisi, Lemuel and Alexander, Daniel C and Rav√¨, Daniele},
   title     = {Enhancing Spatiotemporal Disease Progression Models via Latent Diffusion and Prior Knowledge},
   booktitle = {International Conference on Medical Image Computing and Computer Assisted Intervention},
   year      = {2024},
   selected  = {true},
   comment   = {MICCAI 2024},
   preview   = {brlp-plot-2.gif},
   pdf       = {https://arxiv.org/pdf/2405.03328},
   code      = {https://github.com/LemuelPuglisi/BrLP},
   abstract  = {In this work, we introduce Brain Latent Progression (BrLP), a novel spatiotemporal disease progression model based on latent diffusion. BrLP is designed to predict the evolution of diseases at the individual level on 3D brain MRIs. Existing deep generative models developed for this task are primarily data-driven and face challenges in learning disease progressions. BrLP addresses these challenges by incorporating prior knowledge from disease models to enhance the accuracy of predictions. To implement this, we propose to integrate an auxiliary model that infers volumetric changes in various brain regions. Additionally, we introduce Latent Average Stabilization (LAS), a novel technique to improve spatiotemporal consistency of the predicted progression. BrLP is trained and evaluated on a large dataset comprising 11,730 T1-weighted brain MRIs from 2,805 subjects, collected from three publicly available, longitudinal Alzheimer's Disease (AD) studies. In our experiments, we compare the MRI scans generated by BrLP with the actual follow-up MRIs available from the subjects, in both cross-sectional and longitudinal settings. BrLP demonstrates significant improvements over existing methods, with an increase of 22\% in volumetric accuracy across AD-related brain regions and 43\% in image similarity to the ground-truth scans. The ability of BrLP to generate conditioned 3D scans at the subject level, along with the novelty of integrating prior knowledge to enhance accuracy, represents a significant advancement in disease progression modeling, opening new avenues for precision medicine. The code of BrLP is available at the following link: https://github.com/LemuelPuglisi/BrLP.},
   demo      = {https://youtu.be/6YKz2MNM4jg?si=gE_4Q_cDMzaOTReE},
}

@inproceedings{puglisi2023deepbrainprint,
   author    = {Puglisi, Lemuel and Eshaghi, Arman and Parker, Geoff and Barkhof, Frederik and Alexander, Daniel C and Ravi, Daniele},
   title     = {DeepBrainPrint: A Novel Contrastive Framework for Brain MRI Re-Identification},
   booktitle = {Medical Imaging with Deep Learning},
   year      = {2023},
   selected  = {true},
   comment   = {MIDL 2023},
   preview   = {deepbrainprint-plot.png},
   pdf       = {deepbrainprint-article.pdf},
   poster    = {deepbrainprint-poster.pdf}, 
   code      = {https://github.com/DeepBrainPrint/DeepBrainPrint},
   abstract  = {Recent advances in MRI have led to the creation of large datasets. With the increase in data volume, it has become difficult to locate previous scans of the same patient within these datasets (a process known as re-identification). To address this issue, we propose an AI-powered medical imaging retrieval framework called DeepBrainPrint, which is designed to retrieve brain MRI scans of the same patient. Our framework is a semi-self-supervised contrastive deep learning approach with three main innovations. First, we use a combination of self-supervised and supervised paradigms to create an effective brain fingerprint from MRI scans that can be used for real-time image retrieval. Second, we use a special weighting function to guide the training and improve model convergence. Third, we introduce new imaging transformations to improve retrieval robustness in the presence of intensity variations (i.e. different scan contrasts), and to account for age and disease progression in patients. We tested DeepBrainPrint on a large dataset of T1-weighted brain MRIs from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and on a synthetic dataset designed to evaluate retrieval performance with different image modalities. Our results show that DeepBrainPrint outperforms previous methods, including simple similarity metrics and more advanced contrastive deep learning frameworks.},
}

@inproceedings{ravi2023efficient,
   author    = {Daniele Ravi and Frederik Barkhof and Daniel C. Alexander and Lemuel Puglisi and Geoffrey JM Parker and Arman Eshaghi},
   title     = {An efficient semi-supervised quality control system trained using physics-based MRI-artefact generators and adversarial training}, 
   booktitle = {Medical Image Analysis},
   year      = {2024},
   selected  = {false},
   comment   = {Medical Image Analysis},
   preview   = {automatic-qc-preview.png},
   pdf       = {https://www.sciencedirect.com/science/article/pii/S1361841523002931},
   code      = {https://github.com/Queen-Square-Analytics/automatic-quality-control},
   abstract  = {Large medical imaging data sets are becoming increasingly available, but ensuring sample quality without significant artefacts is challenging. Existing methods for identifying imperfections in medical imaging rely on data-intensive approaches, compounded by a scarcity of artefact-rich scans for training machine learning models in clinical research. To tackle this problem, we propose a framework with four main components: 1) artefact generators inspired by magnetic resonance physics to corrupt brain MRI scans and augment a training dataset, 2) abstract and engineered features to represent images compactly, 3) a feature selection process depending on the artefact class to improve classification, and 4) SVM classifiers to identify artefacts. Our contributions are threefold: first, physics-based artefact generators produce synthetic brain MRI scans with controlled artefacts for data augmentation. This will avoid the labour-intensive collection and labelling process of scans with rare artefacts. Second, we propose a pool of abstract and engineered image features to identify 9 different artefacts for structural MRI. Finally, we use an artefact-based feature selection block that, for each class of artefacts, finds the set of features providing the best classification performance. We performed validation experiments on a large data set of scans with artificially-generated artefacts, and in a multiple sclerosis clinical trial where real artefacts were identified by experts, showing that the proposed pipeline outperforms traditional methods. In particular, our data augmentation increases performance by up to 12.5 percentage points on accuracy, precision, and recall. The computational efficiency of our pipeline enables potential real-time deployment, promising high-throughput clinical applications through automated image-processing pipelines driven by quality control systems.},
}